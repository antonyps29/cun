# ğŸ“Š PredicciÃ³n de Ventas y Carga de Datos a PostgreSQL y Supabase

Este proyecto implementa un pipeline automatizado de anÃ¡lisis de ventas que incluye generaciÃ³n de datos, entrenamiento de un modelo de predicciÃ³n y carga a bases de datos. Ideal para pruebas tÃ©cnicas, prÃ¡cticas de ciencia de datos o despliegues en entornos de negocio controlados.

---

## ğŸ“ Estructura del Proyecto

El pipeline estÃ¡ compuesto por tres scripts Python, cada uno con su respectivo archivo `.bat` para ejecuciÃ³n automatizada:

1. **ETL (`ETL.py`)**
   - Genera datos sintÃ©ticos de ventas.
   - Extrae datos de temperatura de BogotÃ¡ desde una API.
   - Limpia nulos y outliers.

2. **Modelo (`modelo.py`)**
   - Entrena un modelo de series temporales con machine learning (skforecast).
   - Predice ventas y guarda resultados en `data_predicha.csv`.

3. **Carga (`load_db.py`)**
   - Carga los datos a PostgreSQL local.
   - Exporta y sincroniza la tabla con Supabase.
   - Calcula RMSE por categorÃ­a.

Cada script tiene un archivo `.bat` asociado que genera un log (`.txt`) del proceso.

---

## ğŸ§­ Instrucciones de Uso

### 1. ğŸ“Œ Requisitos Previos

- Tener instalado **Anaconda** o **Miniconda**.
- Tener instalado **PostgreSQL local** (puerto por defecto 5433).
- Tener cuenta y proyecto en **Supabase** con base de datos PostgreSQL activa.

### 2. âš™ï¸ InstalaciÃ³n y Entorno

1. Crea un nuevo entorno de Conda:

```bash
conda create -n cun_env python=3.10
conda activate cun_env
```

2. Instala los paquetes necesarios:

```bash
pip install numpy pandas scikit-learn skforecast==0.12.0 jupyter sqlalchemy psycopg2-binary
```

3. (Opcional) Instala Jupyter Notebook:

```bash
pip install notebook
```

---

## ğŸš€ EjecuciÃ³n Paso a Paso

### âœ… 1. Ejecutar ETL

```bash
etl.bat
```

- Ejecuta `ETL.py`
- Genera y limpia los datos
- Log generado: `etl_log.txt`

### ğŸ“ˆ 2. Ejecutar el Modelo

```bash
modelo.bat
```

- Ejecuta `modelo.py`
- Entrena modelo de predicciÃ³n de ventas
- Exporta archivo `data_predicha.csv`
- Log generado: `modelo_log.txt`

### ğŸ—ƒï¸ 3. Cargar Datos en PostgreSQL y Supabase

```bash
load_db.bat
```

- Ejecuta `load_db.py`
- Sube los datos a PostgreSQL
- Crea copia en Supabase
- Calcula el RMSE por categorÃ­a
- Log generado: `load_db_log.txt`

---

## ğŸ”§ ConfiguraciÃ³n

### ğŸ” Rutas del Entorno

AsegÃºrate de modificar en los archivos `.bat` esta lÃ­nea:

```bat
CALL C:\Users\TU_USUARIO\anaconda3\Scripts\activate.bat cun_env
```

Reemplaza `TU_USUARIO` con tu nombre de usuario real en Windows y verifica que `cun_env` sea el nombre correcto del entorno.

---

## ğŸ“ Logs

Cada `.bat` genera un archivo `.log` o `.txt` donde se guarda el detalle del proceso y los errores:

- `etl_log.txt`
- `modelo_log.txt`
- `load_db_log.txt`

---

## ğŸ› ï¸ PersonalizaciÃ³n

- Modifica las credenciales de PostgreSQL y Supabase en `load_db.py` si usas otros puertos, hosts o contraseÃ±as.
- AsegÃºrate de que la base de datos local `prueba_cun` estÃ© creada antes de ejecutar.

---

## ğŸ•’ AutomatizaciÃ³n Diaria (Programador de Tareas de Windows)

Puedes ejecutar automÃ¡ticamente el pipeline todos los dÃ­as a las 8:00 AM:

### 1. Abrir el Programador de Tareas:
- Buscar "Programador de tareas" en el menÃº de Windows.

### 2. Crear una tarea bÃ¡sica:
- **Nombre:** `Ejecutar_Pipeline_Ventas`
- **Desencadenador:** Todos los dÃ­as a las 8:00 AM
- **AcciÃ³n:** Iniciar un programa
- **Programa/script:** 
```bash
cmd.exe
```
- **Agregar argumentos:** 
```bash
/c "C:\Users\usuario\Documents\Prueba Tecnica DS\CUN\etl.bat" && "C:\Users\usuario\Documents\Prueba Tecnica DS\CUN\modelo.bat" && "C:\Users\usuario\Documents\Prueba Tecnica DS\CUN\load_db.bat"
```

> âš ï¸ AsegÃºrate de ajustar las rutas reales segÃºn la ubicaciÃ³n de los archivos `.bat`.

---

## ğŸ“¦ Dependencias

- `pandas`
- `numpy`
- `sklearn`
- `skforecast==0.12.0`
- `sqlalchemy`
- `psycopg2-binary`
- `jupyter` (opcional)

---

## ğŸ§ª ValidaciÃ³n

- Revisa las tablas generadas en PostgreSQL y Supabase.
- AsegÃºrate de que el archivo `data_predicha.csv` contenga las predicciones.
- Verifica los logs para posibles errores.

---

## ğŸ“¬ Contacto

Si tienes preguntas, sugerencias o deseas colaborar, no dudes en crear un issue o contactarme directamente.